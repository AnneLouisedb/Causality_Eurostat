{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daylight Saving Effect on Heart Attack\n",
    "\n",
    "We will use the [healthcare dataset from Kaggle](https://www.kaggle.com/datasets/prasad22/healthcare-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dowhy.causal_identifier import backdoor\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import PC\n",
    "from pgmpy.models import BayesianModel\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation and Data Processing - 10% of the grade\n",
    "\n",
    "Motivation, description of dataset and causal questions, description of assumptions, show true causal graph or a reasonable guess (10% grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/mara/workspace/Causality_Eurostat/data/healthcare/healthcare_dataset.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider the first visit of patients with hypertension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['Medical Condition'] == 'Hypertension']\n",
    "filtered_df = filtered_df[~filtered_df['Name'].duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique values each variable has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    print(f'{col_name}:{filtered_df[col_name].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide that the following variables are irrelevant for our analysis or have arbitrary data: ```['Doctor', 'Hospital', 'Room Number', 'Discharge Date']```. We can also drop ```'Name'``` since we already filtered by the first visit of unique individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop(columns=['Doctor', 'Hospital', 'Room Number', 'Discharge Date', 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the unique values of the columns with less than 10 unique values. We print the column names contianing continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = []\n",
    "\n",
    "for col_name in filtered_df.columns:\n",
    "    if filtered_df[col_name].nunique() <= 10:\n",
    "        print(f'{col_name}:{filtered_df[col_name].unique()}')\n",
    "        categoricals.append(col_name)\n",
    "    else:\n",
    "        print(f'{col_name} is a continuous variable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to introduce a binary column: assigning a value of 1 if the admission date falls within a 3-month window surrounding the annual daylight saving time change in March (a period during which individuals typically adjust their schedules due to a one-hour reduction in sleep), and 0 otherwise. Our dataset spans the years 2018-2023, and we construct a dictionary pairing each year with the specific date of the daylight saving time transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daylight_saving_dates = {\n",
    "    2018: '2018-03-25',\n",
    "    2019: '2019-03-31',\n",
    "    2020: '2020-03-29',\n",
    "    2021: '2021-03-28',\n",
    "    2022: '2022-03-27',\n",
    "    2023: '2023-03-26'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daylight_saving_dates = {year: pd.to_datetime(date) for year, date in daylight_saving_dates.items()}\n",
    "\n",
    "filtered_df['daylight_saving_march'] = filtered_df['Date of Admission'].apply(lambda date: 1 \n",
    "                                                                        if daylight_saving_dates[pd.to_datetime(date).year] <= pd.to_datetime(date) <= daylight_saving_dates[pd.to_datetime(date).year] + pd.DateOffset(months=3)\n",
    "                                                                        else 0)\n",
    "\n",
    "filtered_df['daylight_saving_before_march'] = filtered_df['Date of Admission'].apply(lambda date: 1 \n",
    "                                                                        if daylight_saving_dates[pd.to_datetime(date).year] >= pd.to_datetime(date) >= daylight_saving_dates[pd.to_datetime(date).year] - pd.DateOffset(months=3)\n",
    "                                                                        else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how balanced is our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    if filtered_df[col_name].nunique() <= 10:\n",
    "        print(filtered_df[col_name].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that 25% of Hypertension cases happen within 3 months after the daylight saving in March, whil 22% of the hypertension cases happen before the daylight saving time. Of course this is not enough, we shall see if the daylight saving actually affects the changes of getting hypertension. We come with our own hypothesis before applying any causal discovery algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    print(col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already form some hypothesis. We can motivate to follow this work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_variables = ['Age', 'Gender', 'Medical Condition',\n",
    "             'Insurance Provider', 'Billing Amount', 'Admission Type', \n",
    "             'Medication', 'Test Results', 'daylight_saving_march']\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(graph_variables)\n",
    "\n",
    "edges = [\n",
    "    ('daylight_saving_march', 'Medical Condition'),\n",
    "    ('Age', 'Medical Condition'),\n",
    "    ('Age', 'daylight_saving_march'),\n",
    "    ('Gender', 'Medical Condition'),\n",
    "    ('Admission Type', 'daylight_saving_march'),\n",
    "    ('Medical Condition', 'Medication'),\n",
    "    ('Age', 'Insurance Provider'),\n",
    "    ('Admission Type', 'Test Results'),\n",
    "    ('Billing Amount', 'Medical Condition'),\n",
    "    ('Age', 'Billing Amount'),\n",
    "    ('Insurance Provider', 'Billing Amount'),\n",
    "    ('Test Results', 'Medication')\n",
    "]\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, font_size=8, node_size=700, node_color='skyblue', font_color='black', font_weight='bold', arrowsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - 15% of the grade\n",
    "\n",
    "Testing correlations/conditional independences (15% grade, follow Tutorial 1&2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all paths from between two nodes: ```daylight_saving_march``` and ```Medical Condition```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = list(nx.all_simple_paths(G.to_undirected(), source='daylight_saving_march', target='Medical Condition'))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(all_paths), figsize=(50, 10))\n",
    "for path, ax in zip(all_paths, axs):\n",
    "    edges_on_path = [(source, target) for source, target in zip(path[:-1], path[1:])]\n",
    "    edge_color = ['r' if edge in edges_on_path else 'black' for edge in G.to_undirected().edges()]\n",
    "    nx.draw_shell(G, with_labels=True, node_color=['w', 'w', 'r', 'w', 'w', 'w', 'w', 'w', 'r'], edgecolors='black', ax=ax, edge_color=edge_color)\n",
    "    ax.set_title(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "X = ['daylight_saving_march']\n",
    "Y = ['Medical Condition']\n",
    "\n",
    "Z = [variable for variable in graph_variables if variable not in X + Y]\n",
    "\n",
    "all_comb = []\n",
    "for r in range(1, len(Z) + 1):\n",
    "    all_comb.extend(combinations(Z, r))\n",
    "\n",
    "for combination in all_comb:\n",
    "    print('Node daylight_saving_march and Medical Condition are d-separated by {}: {}'.format(path, nx.algorithms.d_separated(G=G, x=set(['daylight_saving_march']), y=set(['Medical Condition']), z=set(combination))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import pingouin as pg\n",
    "\n",
    "def test_all(df, vars):\n",
    "    # Marginal\n",
    "    for var1, var2 in permutations(vars, 2):\n",
    "        p_val = pg.partial_corr(data=df, x=var1, y=var2, covar=[], method='pearson')['p-val'].item()\n",
    "        print('{} and {}: p-value is {}'.format(var1, var2, p_val))\n",
    "\n",
    "    # Conditional\n",
    "    for var1, var2, cond in permutations(vars, 3):\n",
    "        p_val = pg.partial_corr(data=df, x=var1, y=var2, covar=[cond], method='pearson')['p-val'].item()\n",
    "        print('{} and {} given {}: p-value is {}'.format(var1, var2, cond, p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categoricals(df):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = encode_categoricals(filtered_df)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(df_encoded, graph_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify estimands for backdoor, frontdoor criterion and IVs - 20% of the grade\n",
    "\n",
    "If they apply, or explain why they don't apply (20% grade, follow Tutorial 3 and 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the causal effects - 15% of the grade\n",
    "\n",
    "(e.g. linear, inverse propensity weighting, two stage linear-regression etc) to the estimands you have previously identified (15% grade, follow Tutorial 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal discovery results - 20% of the grade\n",
    "\n",
    "for at least one constraint-based (e.g. SGS, PC) and score-based algorithm (e.g. GES), explain why it works or it doesn't and what is identifiable (20% grade, follow Tutorials 5 and 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and sensitivity analysis - 20% of the grade\n",
    "\n",
    "(e.g. refutation analysis in DoWhy) and Discussion on the assumptions and results (20% grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
