{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daylight Saving Effect on Heart Attack\n",
    "\n",
    "We will use the [healthcare dataset from Kaggle](https://www.kaggle.com/datasets/prasad22/healthcare-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dowhy.causal_identifier import backdoor\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import PC\n",
    "from pgmpy.models import BayesianModel\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import os\n",
    "import cdt\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from itertools import combinations\n",
    "# cdt.SETTINGS.rpath = '/usr/lib/R/bin/Rscript' # for macOS\n",
    "# cdt.SETTINGS.rpath = 'C:\\Program Files\\R\\R-4.3.2\\bin\\Rscript' # for Windows\n",
    "from numpy.random import normal\n",
    "import pingouin as pg\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation and Data Processing - 10% of the grade\n",
    "\n",
    "Motivation, description of dataset and causal questions, description of assumptions, show true causal graph or a reasonable guess (10% grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up one directory from the current working directory\n",
    "os.chdir('..')\n",
    "\n",
    "# Navigate to the 'data' directory\n",
    "os.chdir('data')\n",
    "\n",
    "file_path = 'healthcare/healthcare_dataset.csv'\n",
    "# currently folder/heartattack\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'data/healthcare/healthcare_dataset.csv'\n",
    "# df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the unique medical conditions in the 'Medical Condition' feature into one-hot encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Medical Condition'].value_counts())\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df['Medical Condition'], dtype='int')], axis=1)\n",
    "df = df.drop(columns='Medical Condition')\n",
    "df = df.drop(columns=['Asthma', 'Cancer', 'Arthritis', 'Obesity', 'Diabetes'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep first entry of the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[~df['Name'].duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique values each variable has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    print(f'{col_name}:{filtered_df[col_name].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide that the following variables are irrelevant for our analysis or have arbitrary data: ```['Doctor', 'Hospital', 'Room Number', 'Discharge Date']```. We can also drop ```'Name'``` since we already filtered by the first visit of unique individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop(columns=['Doctor', 'Hospital', 'Room Number', 'Discharge Date', 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the unique values of the columns with less than 10 unique values. We print the column names containing continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = []\n",
    "\n",
    "for col_name in filtered_df.columns:\n",
    "    if filtered_df[col_name].nunique() <= 10:\n",
    "        print(f'{col_name}:{filtered_df[col_name].unique()}')\n",
    "        categoricals.append(col_name)\n",
    "    else:\n",
    "        print(f'{col_name} is a continuous variable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to introduce a binary column: assigning a value of 1 if the admission date falls within a 3-month window surrounding the annual daylight saving time change in March (a period during which individuals typically adjust their schedules due to a one-hour reduction in sleep), and 0 otherwise. Our dataset spans the years 2018-2023, and we construct a dictionary pairing each year with the specific date of the daylight saving time transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daylight_saving_dates = {\n",
    "    2018: '2018-03-25',\n",
    "    2019: '2019-03-31',\n",
    "    2020: '2020-03-29',\n",
    "    2021: '2021-03-28',\n",
    "    2022: '2022-03-27',\n",
    "    2023: '2023-03-26'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daylight_saving_dates = {year: pd.to_datetime(date) for year, date in daylight_saving_dates.items()}\n",
    "\n",
    "filtered_df['Date of Admission'] = pd.to_datetime(filtered_df['Date of Admission'])\n",
    "\n",
    "filtered_df['daylight_saving_march'] = filtered_df['Date of Admission'].apply(lambda date: 1 \n",
    "                                                                        if daylight_saving_dates[date.year] <= date <= daylight_saving_dates[date.year] + pd.DateOffset(days=10)\n",
    "                                                                        else 0)\n",
    "\n",
    "filtered_df['daylight_saving_before_march'] = filtered_df['Date of Admission'].apply(lambda date: 1 \n",
    "                                                                        if daylight_saving_dates[date.year] >= date >= daylight_saving_dates[date.year] - pd.DateOffset(days=10)\n",
    "                                                                        else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how balanced is our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    if filtered_df[col_name].nunique() <= 10:\n",
    "        print(filtered_df[col_name].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER daylight saving time (from last sunday of march)\n",
    "n_hyp = filtered_df[filtered_df.Hypertension == 1].shape[0]\n",
    "n_hyp_after = filtered_df[filtered_df.Hypertension == 1][filtered_df['daylight_saving_march'] == 1].shape[0]\n",
    "perc_hyp_after = (n_hyp_after / n_hyp)*100\n",
    "\n",
    "n_after_march = filtered_df[filtered_df['daylight_saving_march'] == 1].shape[0]\n",
    "perc_hyp_after_total = (n_hyp_after / n_after_march) * 100\n",
    "print(f'Of the {round(n_hyp, 2)} admissions for hypertension, {round(perc_hyp_after, 2)} percent was in the 3 months AFTER daylight saving in march')\n",
    "print(f'This formed {round(perc_hyp_after_total, 2)} percent of the total of {round(n_after_march, 2)} admissions for any condition in the same time period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE daylight saving march\n",
    "n_hyp_before = filtered_df[filtered_df.Hypertension == 1][filtered_df['daylight_saving_before_march'] == 1].shape[0]\n",
    "perc_hyp_before = (n_hyp_before / n_hyp)*100\n",
    "\n",
    "n_before_march = filtered_df[filtered_df['daylight_saving_before_march'] == 1].shape[0]\n",
    "perc_hyp_before_total = (n_hyp_before / n_before_march) * 100\n",
    "print(f'Of the {round(n_hyp, 2)} admissions for hypertension {round(perc_hyp_before, 2)} percent was in the 3 months BEFORE daylight saving in march')\n",
    "print(f'This formed {round(perc_hyp_before_total, 2)} percent of the total of {round(n_before_march, 2)} admissions for any condition in the same time period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that 25.31% of Hypertension cases happen within 3 months after the daylight saving in March, while 22.38% of the hypertension cases happen before the daylight saving time. The trend of increased admissions in the three months following daylight saving time compared to the preceding months, may suggest a seasonal pattern which is potentially applicable to admissions for other medical conditions as well. Therefore, it is noteworthy that the proportion of Hypertension cases among all hospital admissions is also greater in the three months following the daylight saving time change compared to the three months preceding the time change. Of course this is not enough, we shall see if the daylight saving actually affects the changes of getting hypertension. We come with our own hypothesis before applying any causal discovery algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the seasonal patterns in hospital admissions and compare it with the trends observed among patients diagnosed with Hypertension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: y-axis does not start at 0\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# admitted patients without hypertension\n",
    "plt.subplot(1, 2, 1)\n",
    "doy_frequency = filtered_df['Date of Admission'][filtered_df.Hypertension == 0].apply(lambda x: x.month).value_counts().sort_index(ascending=True)\n",
    "plt.step(doy_frequency.index, doy_frequency.values, where='post', color='blue', alpha=0.7)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title('Monthly Hospital Admissions for Patients without Hypertension')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Admitted Patients')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# admitted patients with hypertension\n",
    "plt.subplot(1, 2, 2)\n",
    "doy_frequency = filtered_df['Date of Admission'][filtered_df.Hypertension == 1].apply(lambda x: x.month).value_counts().sort_index(ascending=True)\n",
    "plt.step(doy_frequency.index, doy_frequency.values, where='post', color='blue', alpha=0.7)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title('Monthly Hospital Admissions for Patients with Hypertension')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Admitted Patients')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEMPorary Conclusion of graphs:\n",
    "\n",
    "In the graph depicting the number of patients admitted to the hospital for Hypertension, the two months following the end of March (considering that daylight saving time starts on the last Sunday of March) exhibit higher admission counts compared to the preceding months. On the other hand, when examining all admissions irrespective of medical conditions, the month of February shows significantly fewer admissions. However, January displays admission counts similar to those observed in the months immediately following the end of March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary: check age over months\n",
    "tempdf = filtered_df.copy()\n",
    "tempdf['Month'] = filtered_df['Date of Admission'].apply(lambda x: x.month)\n",
    "\n",
    "tempdf.groupby(['Month']).agg({'Age':'mean'}).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    print(col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already form some hypothesis. We can motivate to follow this work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_variables = ['Age', 'Gender', 'Insurance Provider', 'Billing Amount', \n",
    "                   'Admission Type', 'Medication', 'Test Results', 'Hypertension', 'daylight_saving_march'] #, 'Arthritis', 'Asthma', 'Cancer', 'Diabetes', 'Obesity',]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(graph_variables)\n",
    "\n",
    "edges = [\n",
    "    ('Insurance Provider', 'Billing Amount'),       # decides the billing amount\n",
    "    ('Age', 'Billing Amount'),                      # older people require more care for same treatment\n",
    "    ('Age', 'Insurance Provider'),                  # marketing or preference by age\n",
    "    ('Age', 'Hypertension'),                        # blood pressure rises and likelihood of hypertension \n",
    "    ('Age', 'Medication'),                          # older people might get different medication\n",
    "    ('Gender', 'Hypertension'),                     # hormonal reasons maybe influnece the likelihood of hypertension\n",
    "    ('Gender', 'Medication'),                       # not all medicine apply to men or women\n",
    "    ('Hypertension', 'Test Results'),           \n",
    "    ('Test Results', 'Medication'),\n",
    "    ('Medication', 'Billing Amount'),               # billing amount is dependent on the prescribed medication\n",
    "    ('daylight_saving_march', 'Hypertension'),      # hypothesis: due to lack of sleep\n",
    "    ('Admission Type', 'Billing Amount'),           # emerGgency requires more money\n",
    "    ('daylight_saving_march', 'Admission Type'),    # ?? the period after spring DST effects the number of emergencies etc.\n",
    "    ('Age', 'daylight_saving_march'),               # ?? confounder: see explanation below\n",
    "]\n",
    "\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "node_size = [800 if node in graph_variables else 200 for node in G.nodes]\n",
    "node_color = ['skyblue' if node in graph_variables else 'lightgray' for node in G.nodes]\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, font_size=6, node_size=node_size, node_color=node_color, font_color='black', font_weight='bold', arrowsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cycles\n",
    "list(nx.simple_cycles(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daylight_saving_march is 1 if admission day is within x months after spring DST, else 0. So this indicates a period in which patients are admitted, similarly\n",
    "age influneces if patients are admitted in certain months. For example by the temperature differences which influence for example asthma admissions or hypertension admissions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - 15% of the grade\n",
    "\n",
    "Testing correlations/conditional independences (15% grade, follow Tutorial 1&2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import pingouin as pg\n",
    "\n",
    "def test_all(df, vars):\n",
    "    # Marginal\n",
    "    for var1, var2 in permutations(vars, 2):\n",
    "        p_val = pg.partial_corr(data=df, x=var1, y=var2, covar=[], method='pearson')['p-val'].item()\n",
    "        print('{} and {}: p-value is {}'.format(var1, var2, p_val))\n",
    "\n",
    "    # Conditional\n",
    "    for var1, var2, cond in permutations(vars, 3):\n",
    "        p_val = pg.partial_corr(data=df, x=var1, y=var2, covar=[cond], method='pearson')['p-val'].item()\n",
    "        print('{} and {} given {}: p-value is {}'.format(var1, var2, cond, p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categoricals(df):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to have the partial_corr independence test work we need to have numericals => encode categorical data\n",
    "df_encoded = encode_categoricals(filtered_df)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(df_encoded, graph_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation on Results\n",
    "\n",
    "We expect to get significant p-values for all tests where the graph implies dependece between the variables. We list below some significant conclusions on the p-value.\n",
    "\n",
    "### Independences\n",
    "\n",
    "From the independence tests we can notice the low p-values which are below 0.1 the following imply independence:\n",
    "\n",
    "- gender and insurance provider on their own, but also conditioning on any variable, also accoring to the graph\n",
    "\n",
    "Gender and Insurance Provider: p-value is 0.05167704764915217\n",
    "\n",
    "- insurance provider and billing amount, however in the graph we decided there should be some dependence.\n",
    "\n",
    "Insurance Provider and Billing Amount: p-value is 0.0820549226831016\n",
    "\n",
    "- Insurance provider is also independent from gender, also according to our graph\n",
    "\n",
    "Insurance Provider and Gender: p-value is 0.05167704764915217\n",
    "\n",
    "- medication and daylight saving march, not according with our graph because there is a direct path between the two variables: daylight_saving_march --> Hypertension --> Test Results --> Medication\n",
    "\n",
    "Medication and daylight_saving_march: p-value is 0.05260410622578935\n",
    "\n",
    "### Dependences\n",
    "\n",
    "The high p-values show us the dependence between the variables:\n",
    "- also according to our graph, there is a high dependence between insurance provider and age\n",
    "\n",
    "Insurance Provider and Age: p-value is 0.930665278923154\n",
    "\n",
    "\n",
    "- Insurance Provider and medication are dependent because they are cofounded by Age, also according to our graph\n",
    "\n",
    "Insurance Provider and Medication: p-value is 0.6086810195977133\n",
    "\n",
    "- Hypertension is highly dependent on Insurance Provider, also a conclusion aligning with our graph\n",
    "\n",
    "Insurance Provider and Hypertension: p-value is 0.9939665403739955\n",
    "\n",
    "- Tests Result is highly correlated with daylight saving, also according to our graph. Test Result seems to be dependent on all the variables, this is also reflected in the graph we came up with which seems great.\n",
    "\n",
    "Test Results and daylight_saving_march: p-value is 0.7507855125977744\n",
    "\n",
    "- Billing amount is dependent on gender, not accordyng to our graph.\n",
    "\n",
    "Billing Amount and Gender: p-value is 0.6399470393661836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications of the graph after the independence tests\n",
    "\n",
    "Given the results form the independence tests, we will make the following modifications in our graph:\n",
    "\n",
    "- Insurance provider will not directly affect billing amount\n",
    "- insurance provider directly influences hypertension, and age is a confounder for the two\n",
    "- add an arrow between billing amount and gender\n",
    "- we eliminate medication and test results as nodes because they might be time dependent (is the medication taken after the test results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_variables = ['Age', 'Gender', 'Insurance Provider', 'Billing Amount', \n",
    "                   'Admission Type', 'Hypertension', 'daylight_saving_march'] #, 'Arthritis', 'Asthma', 'Cancer', 'Diabetes', 'Obesity',]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(graph_variables)\n",
    "\n",
    "edges = [\n",
    "    ('Age', 'Billing Amount'),                      # older people require more care for same treatment\n",
    "    ('Age', 'Insurance Provider'),                  # marketing or preference by age\n",
    "    ('Age', 'Hypertension'),                        # blood pressure rises and likelihood of hypertension \n",
    "    ('Gender', 'Hypertension'),                     # hormonal reasons maybe influnece the likelihood of hypertension\n",
    "    ('daylight_saving_march', 'Hypertension'),      # hypothesis: due to lack of sleep\n",
    "    ('Admission Type', 'Billing Amount'),           # emerGgency requires more money\n",
    "    ('daylight_saving_march', 'Admission Type'),    # ?? the period after spring DST effects the number of emergencies etc.\n",
    "    ('Age', 'daylight_saving_march'),               # ?? confounder: see explanation below\n",
    "    ('Insurance Provider', 'Hypertension'),        # independence test modification\n",
    "    ('Billing Amount', 'Gender')\n",
    "]\n",
    "\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "node_size = [800 if node in graph_variables else 200 for node in G.nodes]\n",
    "node_color = ['skyblue' if node in graph_variables else 'lightgray' for node in G.nodes]\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, font_size=6, node_size=node_size, node_color=node_color, font_color='black', font_weight='bold', arrowsize=10)\n",
    "nx.write_gml(G, \"causal_graph.gml\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cycles\n",
    "list(nx.simple_cycles(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify estimands for backdoor, frontdoor criterion and IVs - 20% of the grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding all paths between ```daylight_saving_march``` and ```Hypertension```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = list(nx.all_simple_paths(G.to_undirected(), source='daylight_saving_march', target='Hypertension'))\n",
    "print('Number of paths found:', len(all_paths))\n",
    "\n",
    "if len(all_paths) > 20:\n",
    "    all_paths = all_paths[:20]\n",
    "    \n",
    "n_cols = 3\n",
    "n_rows = (len(all_paths) - 1) // n_cols + 1\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(6 * n_cols, 6 * n_rows))\n",
    "\n",
    "for i, path in enumerate(all_paths):\n",
    "    col = i % n_cols\n",
    "    row = i // n_cols\n",
    "    edges_on_path = [set([source, target]) for source, target in zip(path[:-1], path[1:])]\n",
    "    edge_color = ['r' if set(edge) in edges_on_path else 'black' for edge in G.edges()]  \n",
    "    nx.draw_shell(G, with_labels=True, node_color=['w' if i < len(graph_variables) - 2 else 'r' for i in range(len(graph_variables))], edgecolors='black', ax=axs[row, col], edge_color=edge_color)\n",
    "    axs[row, col].set_title(path[1:-1])\n",
    "    \n",
    "# hide empty plots\n",
    "for i in range(len(all_paths), n_rows * n_cols):\n",
    "    axs.flatten()[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daylight saving martch and hypertension are not d-separated because they have a direct connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backdoor Criterion\n",
    "\n",
    "The backdoor criterion allows us to identify the variables on which we need to condition to calculate our causal estimates. We identify these variables by looking at 'backdoor' paths from ```daylight_saving_march``` and ```Hypertension```. We can apply the backdoor criterion here because there are arrows that go into our treatment, ```daylight_saving_march```, and many confounder on the way for which we need to adjust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import CausalModel\n",
    "\n",
    "# a utility function to parse the .gml file to string\n",
    "def gml_to_string(file):\n",
    "    gml_str = ''\n",
    "    with open(file, 'r') as file:\n",
    "        for line in file:\n",
    "            gml_str += line.rstrip()\n",
    "    return gml_str\n",
    "\n",
    "gml_graph = gml_to_string('causal_graph.gml')\n",
    "# With GML string\n",
    "model=CausalModel(\n",
    "    data = df_encoded,\n",
    "    treatment='daylight_saving_march', \n",
    "    outcome='Hypertension',\n",
    "    graph=gml_graph\n",
    ")\n",
    "model.view_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the backdoor class from DoWhy\n",
    "from dowhy.causal_identifier import backdoor\n",
    "\n",
    "df_encoded.head()\n",
    "\n",
    "# creating a copy of our graph G that is undirected\n",
    "H = G.to_undirected()\n",
    "# all_possible_paths = list(nx.all_simple_paths(H, 'daylight_saving_march', 'Hypertension'))\n",
    "bd = backdoor.Backdoor(G, 'daylight_saving_march','Hypertension')\n",
    "backdoor_paths = [path for path in all_paths if bd.is_backdoor(path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of backdoor paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply the is_backdoor function to each path to check if a path is a backdoor path\n",
    "\n",
    "print('Number of backdoor paths found:', len(backdoor_paths))\n",
    "\n",
    "if len(backdoor_paths) > 20:\n",
    "    backdoor_paths = backdoor_paths[:20]\n",
    "    \n",
    "n_cols = 3\n",
    "n_rows = (len(backdoor_paths) - 1) // n_cols + 1\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(6 * n_cols, 6 * n_rows))\n",
    "\n",
    "for i, path in enumerate(backdoor_paths):\n",
    "    col = i % n_cols\n",
    "    row = i // n_cols\n",
    "    edges_on_path = [set([source, target]) for source, target in zip(path[:-1], path[1:])]\n",
    "    edge_color = ['r' if set(edge) in edges_on_path else 'black' for edge in G.edges()]  \n",
    "    nx.draw_shell(G, with_labels=True, node_color=['w' if i < len(graph_variables) - 2 else 'r' for i in range(len(graph_variables))], edgecolors='black', ax=axs[col], edge_color=edge_color)\n",
    "    axs[col].set_title(path[1:-1])\n",
    "    \n",
    "# hide empty plots\n",
    "for i in range(len(backdoor_paths), n_rows * n_cols):\n",
    "    axs.flatten()[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find three backdoor paths between our treatment and the outcome. Let's analyse what we need to adjust for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustment_variables = pd.DataFrame(columns=['path', 'colliders', 'non_colliders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in backdoor_paths:\n",
    "    colliders = np.array([])\n",
    "    non_colliders = []\n",
    "    path_len = len(path)\n",
    "\n",
    "    # we loop through adjacent variables on the path, ignoring the source and target variables as potential colliders\n",
    "    for node0, node1, node2 in zip(path[0:path_len-2], path[1:path_len-1], path[2:]):\n",
    "        # if there is an arrow pointing into node1 from both sides on the path, it is a collider\n",
    "        if G.has_edge(node0, node1) and G.has_edge(node2, node1):\n",
    "            colliders = np.append(colliders, list(nx.descendants(G,node1)) + [node1]) # so we add it (and all its descendants) to the list\n",
    "    # we flatten the list of list\n",
    "    colliders = colliders.flatten()\n",
    "\n",
    "    # any node on the path (excluding the source and target) that is not a collider is a non-collider\n",
    "    non_colliders = [x for x in path[1:-1] if x not in colliders]\n",
    "\n",
    "    # finally, we add the information to our dataframe, with the path, colliders, and non-colliders\n",
    "    adjustment_variables.loc[len(adjustment_variables.index)] = [path, colliders, non_colliders] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustment_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no colliders on any of the backdoor paths. We need to condition on at least one common non-collider from the three paths found, which are not in the collider set. Therefore, we need to condition on ```Age``` to block all backdoor paths from our treatment ```daylight_saving_march``` to our outcome ```Hypertension```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontdoor Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to also apply the frontdoor criterion. We want to find the adjustment set which satisfies the frontdoor criterion. First of all we need to get all directed paths from ```daylight_saving_march``` and ```Hypertension```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_causal_graph = model._graph\n",
    "our_causal_graph.get_all_directed_paths([\"daylight_saving_march\"], [\"Hypertension\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is a direct edge between our treatment and our outcome, we cannot apply the frontdoor criterion. The adjustment set able to satiisfy this criterion needs to intercent all directed patch from ```daylight_saving_march``` and ```Hypertension``` and because of the direct edge between the two variables, such an adjustment set does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumental Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe there is an unobserved confounder, ```sleep_quality```, between ```daylight_saving_march``` and ```Hypertension``` because one less hour of sleep could directly affect the hypertension risks and the date of admission to the hospital.\n",
    "\n",
    "The only measure that we have which could influece the date of admission (implicitly ```daylight_saving_march```) is ```Age```. Depending on age, people have different routines during the year, moments where stress is higher, or they simply have a higher risk of getting a heart attack.\n",
    "\n",
    "However, ```Age``` cannot be part of the adjustment set for the Instrumental Variables criterion because it has a direct effect on ```Hypertension```. Therefore, there are no variables found to adjust for the iv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoWhy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect()\n",
    "print(identified_estimand)\n",
    "\n",
    "identifier = model.identifier\n",
    "identifier.identify_backdoor(model._graph, model._treatment, model._outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we need to adjust for ```Age``` to block all the backdoor paths. There is no adjustment set found for the frontdoor criterion or the instrumental variables criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the causal effects\n",
    "\n",
    "Given our reasoning from the previous section, we know that we have to condition on ```Age``` to get the true effect of ```daylight_saving_march``` on ```Hypertension```. We apply different estimators from the DoWhy package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate = model.estimate_effect(identified_estimand,\n",
    "        method_name=\"backdoor.linear_regression\")\n",
    "print(causal_estimate)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual Interpreter\n",
    "causal_estimate.interpret(method_name=\"textual_effect_interpreter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a linear estimator we have a causal effect of -0.02849093. We can see that maybe a linear estimator is not the best to apply. We might think that the true nature of our effect and the assumptions made by the estimator do not match entirely. We would expect for a positive causal estimate effect of the ```daylight_saving_march``` and ```Hypertension```. We therefore apply one more estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propensity Score Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate_strat = model.estimate_effect(identified_estimand,\n",
    "                                              method_name=\"backdoor.propensity_score_stratification\",\n",
    "                                              target_units=\"att\")\n",
    "print(causal_estimate_strat)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate_strat.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual Interpreter\n",
    "interpretation = causal_estimate_strat.interpret(method_name=\"textual_effect_interpreter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propensity Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate_match = model.estimate_effect(identified_estimand,\n",
    "                                              method_name=\"backdoor.propensity_score_matching\",\n",
    "                                              target_units=\"atc\")\n",
    "print(causal_estimate_match)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate_match.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual Interpreter\n",
    "interpretation = causal_estimate_match.interpret(method_name=\"textual_effect_interpreter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we finally get a positive effect of the ```daylight_saving_march``` on ```Hypertension``` when using a propensity score matching. Weirdly enough, when the data is startified and using a propensity score we get a causal effect of -0.028. When match units in data instead we obtain a positive causal effect 0.00461."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Causal Graph with Causal Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain skeleton of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes =  graph_variables\n",
    "skeleton = nx.Graph()\n",
    "skeleton.add_nodes_from(nodes)\n",
    "skeleton.add_edges_from(combinations(nodes, 2))\n",
    "\n",
    "nx.draw(skeleton, with_labels=True, node_color='w', edgecolors ='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply independence tests to get the undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize graph lasso\n",
    "import cdt\n",
    "\n",
    "glasso = cdt.independence.graph.Glasso()\n",
    "\n",
    "# apply graph lasso to data\n",
    "df = df_encoded[graph_variables]\n",
    "skeleton = glasso.predict(df) # visualize network\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "nx.draw_networkx(skeleton, font_size=18, font_color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdt\n",
    "pc = cdt.causality.graph.PC(CItest=\"gaussian\", alpha=0.01)\n",
    "\n",
    "pc_graph = pc.create_graph_from_data(df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(pc_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_graph.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_skeleton = cdt.utils.graph.remove_indirect_links(skeleton, alg='aracne')\n",
    "model = cdt.causality.graph.GES()\n",
    "output_graph = model.predict(df, new_skeleton)\n",
    "print(nx.adjacency_matrix(output_graph).todense())\n",
    "\n",
    "nx.draw(output_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using synthetic data based on our prior\n",
    "\n",
    "As we could not find many causal relations and aim to show our implementation of our algorithms further, we simulate data that resembles our real data.\n",
    "<!-- In this case we use less edges. The simulation of synthetic data is a common practise. Real data might be hard to obtain, or due to confidentiality issues it might be hard to get acces to. Privacy especially important in the case of medical data. \n",
    "\n",
    "It is hypothesised that the alteration in time at DST notably affects our sleep patterns. Studies indicate that following the spring time adjustment, more people encounter reduced sleep duration and an increase in disturbances in their sleep cycle. Such disruptions of sleep can lead to elevated heart rate, increased blood pressure, and a heightened risk of arrhythmias.\n",
    "\n",
    "For illustration we add the mediator \"Sleep Quality\" between 'daylight_saving_march' and 'hypertension.  -->\n",
    "We believe that the reason why causal discovery does not work is that the data is not Gaussian. Therefore we want to simulate our own data, corresponding to our graph.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "AGE: X_1 &\\leftarrow \\epsilon_1 & \\epsilon_1 &\\sim \\mathcal N(0,1)\\\\ \n",
    "INSURANCE PROVIDER: X_2 &\\leftarrow X_1 + \\epsilon_2 & \\epsilon_2 &\\sim \\mathcal N(0,0.7)\\\\\n",
    "ADMISSION TYPE: X_3 &\\leftarrow X_7 + \\epsilon_3 & \\epsilon_3 &\\sim \\mathcal N(0,1)\\\\\n",
    "GENDER: X_4 &\\leftarrow X_6 + \\epsilon_4 & \\epsilon_4 &\\sim \\mathcal N(0,1)\\\\\n",
    "HYPERTENSION: X_5 &\\leftarrow X_7 + X_4 + X_1 + X_2 + \\epsilon_5 & \\epsilon_5 &\\sim \\mathcal N(0,1)\\\\\n",
    "BILLING AMOUNT: X_6 &\\leftarrow X_1 + X_3 + \\epsilon_6 & \\epsilon_6 &\\sim \\mathcal N(0,1.5)\\\\\n",
    "DAYLIGHT SAVING MARCH: X_7 &\\leftarrow X_1 + \\epsilon_7 & \\epsilon_7 &\\sim \\mathcal N(0,1)\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=10000\n",
    "\n",
    "eps1 = normal(0, 1, n_samples)\n",
    "eps2 = normal(0, 0.7, n_samples)\n",
    "eps3 = normal(0, 1, n_samples)\n",
    "eps4 = normal(0, 1, n_samples)\n",
    "eps5 = normal(0, 1, n_samples)\n",
    "eps6 = normal(0, 1.5, n_samples)\n",
    "eps7 = normal(0, 1, n_samples)\n",
    "\n",
    "X1 = eps1\n",
    "X2 = X1 + eps2\n",
    "X7= X1 + eps7\n",
    "X3 = X7 + eps3\n",
    "X6 = X1 + X3 + eps6\n",
    "X4 = X6 + eps4\n",
    "X5 = X7 + X4 + X1 + X2 + eps5\n",
    "\n",
    "# we can plot scatter plots between any two variables \n",
    "plt.scatter(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X4, X7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "node_size = [800 if node in graph_variables else 200 for node in G.nodes]\n",
    "node_color = ['skyblue' if node in graph_variables else 'lightgray' for node in G.nodes]\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, font_size=6, node_size=node_size, node_color=node_color, font_color='black', font_weight='bold', arrowsize=10)\n",
    "nx.write_gml(G, \"causal_graph.gml\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENCDA.data_generation.relatedDataframe import RelatedDataframe\n",
    "from GENCDA.data_generation.randomDataframe import randomDataframe\n",
    "\n",
    "num_samples = 1500\n",
    "# Define a DAG\n",
    "graph_variables = ['Age', 'Gender', 'Insurance Provider', 'Billing Amount', \n",
    "                   'Admission Type', 'Hypertension', 'daylight_saving_march']\n",
    "\n",
    "edges = [\n",
    "    ('Age', 'Billing Amount'),                      \n",
    "    ('Age', 'Insurance Provider'),                 \n",
    "    ('Age', 'Hypertension'),                        \n",
    "    ('Gender', 'Hypertension'),                     \n",
    "    ('daylight_saving_march', 'Hypertension'),     \n",
    "    ('Admission Type', 'Billing Amount'),          \n",
    "    ('daylight_saving_march', 'Admission Type'),   \n",
    "    ('Age', 'daylight_saving_march'),            \n",
    "    ('Insurance Provider', 'Hypertension'),\n",
    "    ('Billing Amount', 'Gender')\n",
    "]\n",
    "\n",
    "dag = nx.to_networkx_graph(edges, create_using=nx.DiGraph)\n",
    "\n",
    "random_data = randomDataframe(df)\n",
    "random_data.columns = df.columns\n",
    "\n",
    "print(random_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_synthetic_df = pd.DataFrame({'Age': X1,'Insurance Provider': X2,'Admission Type': X3,'Gender': X4,'Hypertension': X5, 'Billing Amount': X6,'daylight_saving_march': X7})\n",
    "new_synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_synthetic_df = pd.DataFrame({'Age': X1,'Insurance Provider': X2,'Admission Type': X3,'Gender': X4,'Hypertension': X5, 'Billing Amount': X6,'daylight_saving_march': X7})\n",
    "# testing the GES on the newly generated syntehtic data\n",
    "new_skeleton = cdt.utils.graph.remove_indirect_links(skeleton, alg='aracne')\n",
    "model = cdt.causality.graph.GES()\n",
    "output_graph = model.predict(new_synthetic_df, new_skeleton)\n",
    "\n",
    "print(nx.adjacency_matrix(output_graph).todense())\n",
    "\n",
    "nx.draw(output_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the PC on the newly generated syntehtic data\n",
    "pc = cdt.causality.graph.PC(CItest=\"gaussian\", alpha=0.01)\n",
    "\n",
    "pc_graph = pc.create_graph_from_data(new_synthetic_df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(pc_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINGAM\n",
    "import networkx as nx\n",
    "from cdt.causality.graph import LiNGAM\n",
    "\n",
    "obj = LiNGAM()\n",
    "output = obj.predict(new_synthetic_df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(output, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in output.edges():\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIES\n",
    "from cdt.causality.graph import GIES\n",
    "\n",
    "obj = GIES()\n",
    "#The predict() method works without a graph, or with a\n",
    "#directed or undirected graph provided as an input\n",
    "\n",
    "# output = obj.predict(new_synthetic_df)    #No graph provided as an argument\n",
    "# output = obj.predict(new_synthetic_df, nx.Graph(graph))  #With an undirected graph\n",
    "\n",
    "output = obj.predict(new_synthetic_df, dag)  #With a directed graph\n",
    "\n",
    "#To view the graph created, run the below commands:\n",
    "nx.draw_networkx(output, font_size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We test how the daylight saving from March (when usually people's routine starts one hour earlier) has an effect on them being admitted to hospitals with a  hypertension diagnosis. We use a dataset from Kaggle containing synthetic data generated from a true distribution of such admissions. We conduct some data preprocessing where we remove some columns, where we encode the categorical values in numerical ones to be able to apply statistical tests. Be observe some dependencies and independencies in the data and therefore we come up with a graph and assumptions, such as:\n",
    "- age has an influence on the billing amount and insurance provider.\n",
    "\n",
    "From the independence test we find a surprising conclusion:\n",
    "- gender is cause by billing amount\n",
    "Maybe based on how much people's treatment costs gender can be identified.\n",
    "\n",
    "We identify the backdoor paths and conclude that we have to condition on Age in order to get the true causal effect of the daylight saving on people admitted with hypertension. We motivate why there are no frontdoor paths between the treatment and outcome and why instrumental variables cannot be used in our case given our available data.\n",
    "\n",
    "We use a matching propensity score to obtain a very slight positive effect that daylight saving march has on hypertension. We believe that the poor results from the causal estimands is due to the complex nature of our data and the assumptions the estimators make.\n",
    "\n",
    "Up until now we treated our analysis as if the graph was given. We apply causal discovery to our data to learn the causal graph. Unfortunately, the causal discovery techniques did not work on our data very well. We believe this is because out data has not a Gaussian distribution. As future work, we could try and force our data to be Gaussian, or identify the distribution of our data to find better causal graphs. To prove our point, we generate some data according to the true graph and we apply causal discovery algorithms, both constraint-based and score-based.\n",
    "\n",
    "Generally, we believe this is a great starting point for investigating if the nature of our data to construct better results for our hypothesis. We did find surprising dependence relations in the data, but at other times common knowledge could be mapped with the graph.\n",
    "\n",
    "In conclusion, there is a very slight chance that the daylight saving in march has an effect on hypertension given the data we analysed. Maybe applying the same reasoning to other data could help get more generalized results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
