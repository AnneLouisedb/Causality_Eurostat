{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daylight Saving Effect on Hypertension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dowhy.causal_identifier import backdoor\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import PC\n",
    "from pgmpy.models import BayesianModel\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import os\n",
    "import cdt\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from itertools import combinations\n",
    "# cdt.SETTINGS.rpath = '/usr/lib/R/bin/Rscript' # for macOS\n",
    "# cdt.SETTINGS.rpath = 'C:\\Program Files\\R\\R-4.3.2\\bin\\Rscript' # for Windows\n",
    "from numpy.random import normal\n",
    "import pingouin as pg\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation and Data Processing\n",
    "\n",
    "Motivation, description of dataset and causal questions, description of assumptions, show true causal graph or a reasonable guess (10% grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use is the [healthcare dataset from Kaggle](https://www.kaggle.com/datasets/prasad22/healthcare-dataset). It contains 10,000 rows where each row represents a patients healthcare record. To guarantee patients' privacy and comply with healthcare regulations, no real patient information is used. Instead the data is generated based on actual healthcare records and it is made to consist of a similar structure and contain similar attributes. It seems to be oriented at healthcare records from the United States based on the generated data, although no clarity is provided regarding their sources on their Kaggle page. The dataset captures observations from individual patient healthcare records, indicating its observational nature.\n",
    "\n",
    "The dataset includes the medical condition for which the patients are admitted to the hospital. We will focus on the hypertension condition which is an sustained increase in blood pressure. Untreated hypertension can according to the [WHO](https://www.who.int/news-room/fact-sheets/detail/hypertension), among other problems, cause heart- and vascular diseases and can lead to life threatening complications such as a heart attack or heart failure. \n",
    "\n",
    "\n",
    "Hypertension can have a variety of causes. One of which is the increase of blood pressure due to a shortage of sleep [(Palagini et al., 2013)](https://www.researchgate.net/profile/Dieter-Riemann/publication/233749083_Sleep_Loss_and_Hypertension_A_Systematic_Review/links/0fcfd50b9d9236bbfd000000/Sleep-Loss-and-Hypertension-A-Systematic-Review.pdf). This forms the basis for our causal investigation, in which we want to find if the daylight saving time (DST) in the month March (also known as \"spring forward\") causes more patients to be admitted for hypertension. Our reasoning is that the abrupt time change distorts the circadian rhythms of people and additionaly they could suffer from sleep due to the clock being forwarded by 1 hour. We base these assumptions on two papers in which examine the health consquences of the DST time change ([Jiddou et al., 2013](https://www.sciencedirect.com/science/article/abs/pii/S0002914912024435); [Zhang et al., 2020](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007927&campaign_url=https%3A%2F%2Fwww.garnethealth.org%2Fnode&hgcrm_campaign_url=https%3A%2F%2Fwww.garnethealth.org%2Fnode)). Our investigation aims to examine the impact of the daylight saving time (DST) time-shift on the occurrence of hypertension in individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/healthcare/healthcare_dataset.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'data/healthcare/healthcare_dataset.csv'\n",
    "# df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with an insight in the unique medical conditions in the 'Medical Condition' column and create our outcome variable 'Hypertension'. It is a one-hot encoded column containing a 1 if a patient is admitted for hypertension and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Medical Condition'].value_counts())\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df['Medical Condition'], dtype='int')], axis=1)\n",
    "df = df.drop(columns='Medical Condition')\n",
    "df = df.drop(columns=['Asthma', 'Cancer', 'Arthritis', 'Obesity', 'Diabetes'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains multiple entries with the same patient name. We only keep first entry of the same person since we do not want to include subsequent related hosipital admissions since they could span over a longer period than our specic timepoint of the DST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[~df['Name'].duplicated(keep='first')]\n",
    "print(f'{df.shape[0] - filtered_df.shape[0]} entries are removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many unique values each variable has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    print(f'{col_name}:{filtered_df[col_name].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide that the following variables are irrelevant for our analysis or have arbitrary data: ```['Doctor', 'Hospital', 'Room Number', 'Discharge Date']```. We can also drop ```'Name'``` since we already filtered by the first visit of unique individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop(columns=['Doctor', 'Hospital', 'Room Number', 'Discharge Date', 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the unique values of the columns with less than 10 unique values. We print the column names containing continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = []\n",
    "\n",
    "for col_name in filtered_df.columns:\n",
    "    if filtered_df[col_name].nunique() <= 10:\n",
    "        print(f'{col_name}:{filtered_df[col_name].unique()}')\n",
    "        categoricals.append(col_name)\n",
    "    else:\n",
    "        print(f'{col_name} is a continuous variable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the seasonal patterns in hospital admissions and compare it with the trends observed among patients diagnosed with Hypertension. This allows us to determine the range of the period in which we want to look for the effect of the DST time change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: y-axis does not start at 0\n",
    "filtered_df['Date of Admission'] = pd.to_datetime(filtered_df['Date of Admission'])\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# admitted patients without hypertension\n",
    "plt.subplot(1, 2, 1)\n",
    "doy_frequency = filtered_df['Date of Admission'][filtered_df.Hypertension == 0].apply(lambda x: x.month).value_counts().sort_index(ascending=True)\n",
    "plt.step(doy_frequency.index, doy_frequency.values, where='post', color='blue', alpha=0.7)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title('Monthly Hospital Admissions for Patients without Hypertension')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Admitted Patients')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# admitted patients with hypertension\n",
    "plt.subplot(1, 2, 2)\n",
    "doy_frequency = filtered_df['Date of Admission'][filtered_df.Hypertension == 1].apply(lambda x: x.month).value_counts().sort_index(ascending=True)\n",
    "plt.step(doy_frequency.index, doy_frequency.values, where='post', color='blue', alpha=0.7)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title('Monthly Hospital Admissions for Patients with Hypertension')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Admitted Patients')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpreting the graphs, take note that the y-axis do not start at 0, this is done to emphasize the monthly differences.\n",
    "\n",
    "In the graph depicting the number of patients admitted to the hospital for Hypertension, the two months following March (in which DST takes place) exhibit higher admission counts compared to the preceding months. However, when examining the admissions for other medical conditions, the month of February similarly shows significantly fewer admissions than march. \n",
    "\n",
    "To isolate the effect of DST on hypertension, we choose to investigate a 20-day period after DST in spring. The limits the influence of the montly fluctuations in the datset and is in line with similar papers which examine the health effects of the DST time-change. A time-period of a week in [Jiddou et al. (2013)](https://www.sciencedirect.com/science/article/abs/pii/S0002914912024435) and 28 days in [Zhang et al. (2020)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007927&campaign_url=https%3A%2F%2Fwww.garnethealth.org%2Fnode&hgcrm_campaign_url=https%3A%2F%2Fwww.garnethealth.org%2Fnode).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a variable which encodes the DST change in spring, we aim to introduce a binary column: assigning a value of 1 if the admission date falls within a 10-day window surrounding the annual DST change in March (a period during which individuals typically adjust their schedules due to a one-hour reduction in sleep), and 0 otherwise. Our dataset spans the years 2018-2023, and we construct a dictionary pairing each year with the specific date of the daylight saving time transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daylight_saving_dates = {\n",
    "    2018: '2018-03-25',\n",
    "    2019: '2019-03-31',\n",
    "    2020: '2020-03-29',\n",
    "    2021: '2021-03-28',\n",
    "    2022: '2022-03-27',\n",
    "    2023: '2023-03-26'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daylight_saving_dates = {year: pd.to_datetime(date) for year, date in daylight_saving_dates.items()}\n",
    "\n",
    "filtered_df['Date of Admission'] = pd.to_datetime(filtered_df['Date of Admission'])\n",
    "\n",
    "filtered_df['daylight_saving_march'] = filtered_df['Date of Admission'].apply(lambda date: 1 \n",
    "                                                                        if daylight_saving_dates[date.year] <= date <= daylight_saving_dates[date.year] + pd.DateOffset(days=20)\n",
    "                                                                        else 0)\n",
    "\n",
    "filtered_df['daylight_saving_before_march'] = filtered_df['Date of Admission'].apply(lambda date: 1 \n",
    "                                                                        if daylight_saving_dates[date.year] >= date >= daylight_saving_dates[date.year] - pd.DateOffset(days=20)\n",
    "                                                                        else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how balanced is our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    if filtered_df[col_name].nunique() <= 10:\n",
    "        print(filtered_df[col_name].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our estimate of the causal graph\n",
    "We start with reasoning about the relevant variables and their connections to create an estimation for the causal graph afer which we will perform independence tests and correct the graph if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in filtered_df.columns:\n",
    "    print(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_variables = ['Age', 'Gender', 'Insurance Provider', 'Billing Amount', \n",
    "                   'Admission Type', 'Medication', 'Test Results', 'Hypertension', 'daylight_saving_march']\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(graph_variables)\n",
    "\n",
    "edges = [\n",
    "    ('Insurance Provider', 'Billing Amount'),       # Insurance Provider decides the billing amount\n",
    "    ('Age', 'Billing Amount'),                      # Older people require more care for same treatment\n",
    "    ('Age', 'Insurance Provider'),                  # Age focussed marketing or personal preference by age\n",
    "    ('Age', 'Hypertension'),                        # Blood pressure rises with age and likelihood of hypertension \n",
    "    ('Age', 'Medication'),                          # Older people might get different medication\n",
    "    ('Gender', 'Hypertension'),                     # Hormonal reasons and differences in blood pressure between men and women\n",
    "    ('Gender', 'Medication'),                       # Not all medicine apply to men or women\n",
    "    ('Hypertension', 'Test Results'),               # The medical condition influences the outcome of the tests           \n",
    "    ('Test Results', 'Medication'),                 # Medication is prescribed based on the outcome of the tests\n",
    "    ('Medication', 'Billing Amount'),               # Billing amount is dependent on the prescribed medication\n",
    "    ('daylight_saving_march', 'Hypertension'),      # hypothesis: due to lack of sleep and distorted bio rhythm\n",
    "    ('Admission Type', 'Billing Amount'),           # An emergency admission requires more money to e paid\n",
    "    ('daylight_saving_march', 'Admission Type'),    # See explanation below\n",
    "    ('Age', 'daylight_saving_march'),               # See explanation below\n",
    "]\n",
    "\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "node_size = [800 if node in graph_variables else 200 for node in G.nodes]\n",
    "node_color = ['skyblue' if node in graph_variables else 'lightgray' for node in G.nodes]\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, font_size=6, node_size=node_size, node_color=node_color, font_color='black', font_weight='bold', arrowsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cycles\n",
    "list(nx.simple_cycles(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanations for the edges in the graph can be found in the code cell above. Two less obvious connections require additional explaining:\n",
    "1. ('daylight_saving_march' -> 'Admission Type'): 'daylight_saving_march' represents a time-period for the admitted patients in which people can suffer from insufficient sleep or encounter disruptions in their sleep patterns which has impact on individuals' circadian rhythms and overall well-being which effects the requirement of a higher urgency admission.\n",
    "2. ('Age' -> 'daylight_saving_march'): The average age of admitted patients fluctuates during the year due to factors (such as the seasonal wheater or hours of daylight) preventing or causing specific age groups to get admitted to the hospital. Thus, a patient's age influences whether they are admitted during this 20-day time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ('Age' -> 'daylight_saving_march') arrow can be substantiated by looking at the trend of the average age of patients being admitted to the hospital for hypertension. In the plot below we see a fluctuation in the average age per month and the largest difference is April (47.64 year old) and May (53.69 year old), a difference in average age of about 7 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copy of dataframe for plot\n",
    "agedf = filtered_df.copy()\n",
    "agedf['Month'] = agedf[agedf['Hypertension']==1]['Date of Admission'].apply(lambda x: x.month)\n",
    "\n",
    "monthly_age_stats = agedf.groupby(['Month']).agg({'Age': ['mean', 'max', 'min']})\n",
    "\n",
    "# create plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(monthly_age_stats.index, monthly_age_stats['Age']['mean'], marker='o', linestyle='-', color='b', label='Mean Age')\n",
    "\n",
    "# annotate max and min\n",
    "max_val = monthly_age_stats.loc[monthly_age_stats['Age']['mean'].idxmax()]['Age']['mean']\n",
    "min_val = monthly_age_stats.loc[monthly_age_stats['Age']['mean'].idxmin()]['Age']['mean']\n",
    "plt.annotate(f'Max: {max_val:.2f}', xy=(monthly_age_stats['Age']['mean'].idxmax(), max_val), xytext=(10, 10),\n",
    "             textcoords='offset points', arrowprops=dict(facecolor='red', arrowstyle='wedge,tail_width=0.7', alpha=0.5))\n",
    "plt.annotate(f'Min: {min_val:.2f}', xy=(monthly_age_stats['Age']['mean'].idxmin(), min_val), xytext=(10, -20),\n",
    "             textcoords='offset points', arrowprops=dict(facecolor='green', arrowstyle='wedge,tail_width=0.7', alpha=0.5))\n",
    "\n",
    "plt.title('Average Age per Month for Hypertension Admissions')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Age')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence tests\n",
    "Let's identify the correlation between the variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import pingouin as pg\n",
    "\n",
    "def test_all(df, vars):\n",
    "    # Marginal\n",
    "    for var1, var2 in permutations(vars, 2):\n",
    "        p_val = pg.partial_corr(data=df, x=var1, y=var2, covar=[], method='pearson')['p-val'].item()\n",
    "        print('{} and {}: p-value is {}'.format(var1, var2, p_val))\n",
    "\n",
    "    # Conditional\n",
    "    for var1, var2, cond in permutations(vars, 3):\n",
    "        p_val = pg.partial_corr(data=df, x=var1, y=var2, covar=[cond], method='pearson')['p-val'].item()\n",
    "        print('{} and {} given {}: p-value is {}'.format(var1, var2, cond, p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categoricals(df):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have the partial_corr independence test work we need to have numerical columns encoded into categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = encode_categoricals(filtered_df)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(df_encoded, graph_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation on results\n",
    "\n",
    "We expect to get significant p-values for all tests where the graph implies dependece between the variables. We list below some significant conclusions on the p-value.\n",
    "\n",
    "### Independences\n",
    "\n",
    "From the independence tests we can notice the low p-values which are below 0.1 the following imply independence:\n",
    "\n",
    "- gender and insurance provider on their own, but also conditioning on any variable, also accoring to the graph\n",
    "\n",
    "Gender and Insurance Provider: p-value is 0.05167704764915217\n",
    "\n",
    "- insurance provider and billing amount, however in the graph we decided there should be some dependence.\n",
    "\n",
    "Insurance Provider and Billing Amount: p-value is 0.0820549226831016\n",
    "\n",
    "- Insurance provider is also independent from gender, also according to our graph\n",
    "\n",
    "Insurance Provider and Gender: p-value is 0.05167704764915217\n",
    "\n",
    "- medication and daylight saving march, not according with our graph because there is a direct path between the two variables: daylight_saving_march --> Hypertension --> Test Results --> Medication\n",
    "\n",
    "### Dependences\n",
    "\n",
    "The high p-values show us the dependence between the variables:\n",
    "- also according to our graph, there is a high dependence between insurance provider and age\n",
    "\n",
    "Insurance Provider and Age: p-value is 0.930665278923154\n",
    "\n",
    "\n",
    "- Insurance Provider and medication are dependent because they are cofounded by Age, also according to our graph\n",
    "\n",
    "Insurance Provider and Medication: p-value is 0.6086810195977133\n",
    "\n",
    "- Hypertension is highly dependent on Insurance Provider, also a conclusion aligning with our graph\n",
    "\n",
    "Insurance Provider and Hypertension: p-value is 0.9939665403739955\n",
    "\n",
    "- Tests Result is highly correlated with daylight saving, also according to our graph. Test Result seems to be dependent on all the variables, this is also reflected in the graph we came up with which seems great.\n",
    "\n",
    "Test Results and daylight_saving_march: p-value is 0.6844684976503201\n",
    "\n",
    "- Billing amount is dependent on gender, not accordyng to our graph.\n",
    "\n",
    "Billing Amount and Gender: p-value is 0.6399470393661836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications of the graph after the independence tests\n",
    "\n",
    "Given the results form the independence tests, we will make the following modifications in our graph:\n",
    "\n",
    "- Insurance provider will not directly affect billing amount\n",
    "- insurance provider directly influences hypertension, and age is a confounder for the two\n",
    "- add an arrow between billing amount and gender\n",
    "- we eliminate medication and test results as nodes because they might be time dependent (is the medication taken after the test results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_variables = ['Age', 'Gender', 'Insurance Provider', 'Billing Amount', \n",
    "                   'Admission Type', 'Hypertension', 'daylight_saving_march']\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(graph_variables)\n",
    "\n",
    "edges = [\n",
    "    ('Age', 'Billing Amount'),                     \n",
    "    ('Age', 'Insurance Provider'),                 \n",
    "    ('Age', 'Hypertension'),                       \n",
    "    ('Gender', 'Hypertension'),                    \n",
    "    ('daylight_saving_march', 'Hypertension'),     \n",
    "    ('Admission Type', 'Billing Amount'),          \n",
    "    ('daylight_saving_march', 'Admission Type'),   \n",
    "    ('Age', 'daylight_saving_march'),              \n",
    "    ('Insurance Provider', 'Hypertension'),        \n",
    "    ('Billing Amount', 'Gender')\n",
    "]\n",
    "\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "node_size = [800 if node in graph_variables else 200 for node in G.nodes]\n",
    "node_color = ['skyblue' if node in graph_variables else 'lightgray' for node in G.nodes]\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, font_size=6, node_size=node_size, node_color=node_color, font_color='black', font_weight='bold', arrowsize=10)\n",
    "nx.write_gml(G, \"causal_graph.gml\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cycles\n",
    "list(nx.simple_cycles(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the hypertension admission frequencies surrounding DST time-change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing with the causal analysis, lets consider the statstics for patients with hypertension before and after the DST time change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER daylight saving time (from last sunday of march)\n",
    "n_hyp = filtered_df[filtered_df.Hypertension == 1].shape[0]\n",
    "n_hyp_after = filtered_df[filtered_df.Hypertension == 1][filtered_df['daylight_saving_march'] == 1].shape[0]\n",
    "perc_hyp_after = (n_hyp_after / n_hyp)*100\n",
    "\n",
    "n_after_march = filtered_df[filtered_df['daylight_saving_march'] == 1].shape[0]\n",
    "perc_hyp_after_total = (n_hyp_after / n_after_march) * 100\n",
    "print(f'Of the {round(n_hyp, 2)} admissions for hypertension, {round(perc_hyp_after, 2)} percent was in the 20-days AFTER daylight saving in march')\n",
    "print(f'This formed {round(perc_hyp_after_total, 2)} percent of the total of {round(n_after_march, 2)} admissions for any condition in the same time period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE daylight saving march\n",
    "n_hyp_before = filtered_df[filtered_df.Hypertension == 1][filtered_df['daylight_saving_before_march'] == 1].shape[0]\n",
    "perc_hyp_before = (n_hyp_before / n_hyp)*100\n",
    "\n",
    "n_before_march = filtered_df[filtered_df['daylight_saving_before_march'] == 1].shape[0]\n",
    "perc_hyp_before_total = (n_hyp_before / n_before_march) * 100\n",
    "print(f'Of the {round(n_hyp, 2)} admissions for hypertension {round(perc_hyp_before, 2)} percent was in the 20-days BEFORE daylight saving in march')\n",
    "print(f'This formed {round(perc_hyp_before_total, 2)} percent of the total of {round(n_before_march, 2)} admissions for any condition in the same time period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that 5.69% of Hypertension cases happen within 20 days after the daylight saving in March, while 5.06% of the hypertension cases happen before the daylight saving time. \n",
    "\n",
    "From the plot with the patients admitted per month showed that there is a deviation from month to month in the number of admissions. Therefore we also need to look at the proportion of hypertension cases compared to the total hospital admissions.\n",
    "\n",
    "We see that the proportion of Hypertension cases among all hospital admissions is also greater in the 20 days following the DST time change compared to 20 days preceding the time change. This is in line with our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify estimands for backdoor, frontdoor criterion and IVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding all paths between ```daylight_saving_march``` and ```Hypertension```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = list(nx.all_simple_paths(G.to_undirected(), source='daylight_saving_march', target='Hypertension'))\n",
    "print('Number of paths found:', len(all_paths))\n",
    "\n",
    "if len(all_paths) > 20:\n",
    "    all_paths = all_paths[:20]\n",
    "    \n",
    "n_cols = 3\n",
    "n_rows = (len(all_paths) - 1) // n_cols + 1\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(6 * n_cols, 6 * n_rows))\n",
    "\n",
    "for i, path in enumerate(all_paths):\n",
    "    col = i % n_cols\n",
    "    row = i // n_cols\n",
    "    edges_on_path = [set([source, target]) for source, target in zip(path[:-1], path[1:])]\n",
    "    edge_color = ['r' if set(edge) in edges_on_path else 'black' for edge in G.edges()]  \n",
    "    nx.draw_shell(G, with_labels=True, node_color=['w' if i < len(graph_variables) - 2 else 'r' for i in range(len(graph_variables))], edgecolors='black', ax=axs[row, col], edge_color=edge_color)\n",
    "    axs[row, col].set_title(path[1:-1])\n",
    "    \n",
    "# hide empty plots\n",
    "for i in range(len(all_paths), n_rows * n_cols):\n",
    "    axs.flatten()[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daylight_saving_march and Hypertension are not d-separated because they have a direct connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backdoor Criterion\n",
    "\n",
    "The backdoor criterion allows us to identify the variables on which we need to condition to calculate our causal estimates. We identify these variables by looking at 'backdoor' paths from ```daylight_saving_march``` and ```Hypertension```. We can apply the backdoor criterion here because there are arrows that go into our treatment, ```daylight_saving_march```, and many confounders on the way for which we need to adjust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import CausalModel\n",
    "\n",
    "# a utility function to parse the .gml file to string\n",
    "def gml_to_string(file):\n",
    "    gml_str = ''\n",
    "    with open(file, 'r') as file:\n",
    "        for line in file:\n",
    "            gml_str += line.rstrip()\n",
    "    return gml_str\n",
    "\n",
    "gml_graph = gml_to_string('causal_graph.gml')\n",
    "# With GML string\n",
    "model=CausalModel(\n",
    "    data = df_encoded,\n",
    "    treatment='daylight_saving_march', \n",
    "    outcome='Hypertension',\n",
    "    graph=gml_graph\n",
    ")\n",
    "model.view_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the backdoor class from DoWhy\n",
    "from dowhy.causal_identifier import backdoor\n",
    "\n",
    "df_encoded.head()\n",
    "\n",
    "# creating a copy of our graph G that is undirected\n",
    "H = G.to_undirected()\n",
    "# all_possible_paths = list(nx.all_simple_paths(H, 'daylight_saving_march', 'Hypertension'))\n",
    "bd = backdoor.Backdoor(G, 'daylight_saving_march','Hypertension')\n",
    "backdoor_paths = [path for path in all_paths if bd.is_backdoor(path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of backdoor paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we apply the is_backdoor function to each path to check if a path is a backdoor path\n",
    "\n",
    "print('Number of backdoor paths found:', len(backdoor_paths))\n",
    "\n",
    "if len(backdoor_paths) > 20:\n",
    "    backdoor_paths = backdoor_paths[:20]\n",
    "    \n",
    "n_cols = 3\n",
    "n_rows = (len(backdoor_paths) - 1) // n_cols + 1\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(6 * n_cols, 6 * n_rows))\n",
    "\n",
    "for i, path in enumerate(backdoor_paths):\n",
    "    col = i % n_cols\n",
    "    row = i // n_cols\n",
    "    edges_on_path = [set([source, target]) for source, target in zip(path[:-1], path[1:])]\n",
    "    edge_color = ['r' if set(edge) in edges_on_path else 'black' for edge in G.edges()]  \n",
    "    nx.draw_shell(G, with_labels=True, node_color=['w' if i < len(graph_variables) - 2 else 'r' for i in range(len(graph_variables))], edgecolors='black', ax=axs[col], edge_color=edge_color)\n",
    "    axs[col].set_title(path[1:-1])\n",
    "    \n",
    "# hide empty plots\n",
    "for i in range(len(backdoor_paths), n_rows * n_cols):\n",
    "    axs.flatten()[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find three backdoor paths between our treatment and the outcome. Let's analyse what we need to adjust for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustment_variables = pd.DataFrame(columns=['path', 'colliders', 'non_colliders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in backdoor_paths:\n",
    "    colliders = np.array([])\n",
    "    non_colliders = []\n",
    "    path_len = len(path)\n",
    "\n",
    "    # we loop through adjacent variables on the path, ignoring the source and target variables as potential colliders\n",
    "    for node0, node1, node2 in zip(path[0:path_len-2], path[1:path_len-1], path[2:]):\n",
    "        # if there is an arrow pointing into node1 from both sides on the path, it is a collider\n",
    "        if G.has_edge(node0, node1) and G.has_edge(node2, node1):\n",
    "            colliders = np.append(colliders, list(nx.descendants(G,node1)) + [node1]) # so we add it (and all its descendants) to the list\n",
    "    # we flatten the list of list\n",
    "    colliders = colliders.flatten()\n",
    "\n",
    "    # any node on the path (excluding the source and target) that is not a collider is a non-collider\n",
    "    non_colliders = [x for x in path[1:-1] if x not in colliders]\n",
    "\n",
    "    # finally, we add the information to our dataframe, with the path, colliders, and non-colliders\n",
    "    adjustment_variables.loc[len(adjustment_variables.index)] = [path, colliders, non_colliders] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjustment_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no colliders on any of the backdoor paths. We need to condition on at least one common non-collider from the three paths found, which are not in the collider set. Therefore, we need to condition on ```Age``` to block all backdoor paths from our treatment ```daylight_saving_march``` to our outcome ```Hypertension```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontdoor Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to also apply the frontdoor criterion. We want to find the adjustment set which satisfies the frontdoor criterion. First of all we need to get all directed paths from ```daylight_saving_march``` and ```Hypertension```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_causal_graph = model._graph\n",
    "our_causal_graph.get_all_directed_paths([\"daylight_saving_march\"], [\"Hypertension\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is a direct edge between our treatment and our outcome, we cannot apply the frontdoor criterion. The adjustment set able to satiisfy this criterion needs to intercent all directed patch from ```daylight_saving_march``` and ```Hypertension``` and because of the direct edge between the two variables, such an adjustment set does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumental Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe there is an unobserved confounder, ```sleep_quality```, between ```daylight_saving_march``` and ```Hypertension``` because one less hour of sleep could directly affect the hypertension risks and the date of admission to the hospital.\n",
    "\n",
    "The only measure that we have which could influece the date of admission (implicitly ```daylight_saving_march```) is ```Age```. Depending on age, people have different routines during the year, moments where stress is higher, or they simply have a higher risk of getting a heart attack.\n",
    "\n",
    "However, ```Age``` cannot be part of the adjustment set for the Instrumental Variables criterion because it has a direct effect on ```Hypertension```. Therefore, there are no variables found to adjust for the iv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DoWhy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect()\n",
    "print(identified_estimand)\n",
    "\n",
    "identifier = model.identifier\n",
    "identifier.identify_backdoor(model._graph, model._treatment, model._outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we need to adjust for ```Age``` to block all the backdoor paths. There is no adjustment set found for the frontdoor criterion or the instrumental variables criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the causal effects\n",
    "\n",
    "Given our reasoning from the previous section, we know that we have to condition on ```Age``` to get the true effect of ```daylight_saving_march``` on ```Hypertension```. We apply different estimators from the DoWhy package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate = model.estimate_effect(identified_estimand,\n",
    "        method_name=\"backdoor.linear_regression\")\n",
    "print(causal_estimate)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual Interpreter\n",
    "causal_estimate.interpret(method_name=\"textual_effect_interpreter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a linear estimator we have a causal effect of -0.02849093. We can see that maybe a linear estimator is not the best to apply. We might think that the true nature of our effect and the assumptions made by the estimator do not match entirely. We would expect for a positive causal estimate effect of the ```daylight_saving_march``` and ```Hypertension```. We therefore apply one more estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propensity Score Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate_strat = model.estimate_effect(identified_estimand,\n",
    "                                              method_name=\"backdoor.propensity_score_stratification\",\n",
    "                                              target_units=\"att\")\n",
    "print(causal_estimate_strat)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate_strat.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual Interpreter\n",
    "interpretation = causal_estimate_strat.interpret(method_name=\"textual_effect_interpreter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Propensity Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_estimate_match = model.estimate_effect(identified_estimand,\n",
    "                                              method_name=\"backdoor.propensity_score_matching\",\n",
    "                                              target_units=\"atc\")\n",
    "print(causal_estimate_match)\n",
    "print(\"Causal Estimate is \" + str(causal_estimate_match.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual Interpreter\n",
    "interpretation = causal_estimate_match.interpret(method_name=\"textual_effect_interpreter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we finally get a positive effect of the ```daylight_saving_march``` on ```Hypertension``` when using a propensity score matching. Weirdly enough, when the data is startified and using a propensity score we get a causal effect of -0.028. When match units in data instead we obtain a positive causal effect 0.00461."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Causal Graph with Causal Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain skeleton of graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes =  graph_variables\n",
    "skeleton = nx.Graph()\n",
    "skeleton.add_nodes_from(nodes)\n",
    "skeleton.add_edges_from(combinations(nodes, 2))\n",
    "\n",
    "nx.draw(skeleton, with_labels=True, node_color='w', edgecolors ='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply independence tests to get the undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize graph lasso\n",
    "import cdt\n",
    "\n",
    "glasso = cdt.independence.graph.Glasso()\n",
    "\n",
    "# apply graph lasso to data\n",
    "df = df_encoded[graph_variables]\n",
    "skeleton = glasso.predict(df) # visualize network\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "nx.draw_networkx(skeleton, font_size=18, font_color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply PC with ```alpha = [0.01, 0.1, 0.3]``` based on the independence tests we had in one of the previous section where most of the independent variables had a low p-value lower than 0.1. However, 0.1 and 0.3 can also be considered low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdt\n",
    "pc = cdt.causality.graph.PC(CItest=\"gaussian\", alpha=0.01)\n",
    "\n",
    "pc_graph = pc.create_graph_from_data(df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(pc_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_graph.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdt\n",
    "pc = cdt.causality.graph.PC(CItest=\"gaussian\", alpha=0.1)\n",
    "\n",
    "pc_graph = pc.create_graph_from_data(df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(pc_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = cdt.causality.graph.PC(CItest=\"gaussian\", alpha=0.3)\n",
    "\n",
    "pc_graph = pc.create_graph_from_data(df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(pc_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_skeleton = cdt.utils.graph.remove_indirect_links(skeleton, alg='aracne')\n",
    "model = cdt.causality.graph.GES()\n",
    "output_graph = model.predict(df, new_skeleton)\n",
    "print(nx.adjacency_matrix(output_graph).todense())\n",
    "\n",
    "nx.draw(output_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we change the values of alpha, we get very bad graph results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: using synthetic data based on our prior\n",
    "\n",
    "As we could not find many causal relations and aim to show our implementation of our algorithms further, we simulate data that resembles our real data.\n",
    "<!-- In this case we use less edges. The simulation of synthetic data is a common practise. Real data might be hard to obtain, or due to confidentiality issues it might be hard to get acces to. Privacy especially important in the case of medical data. \n",
    "\n",
    "It is hypothesised that the alteration in time at DST notably affects our sleep patterns. Studies indicate that following the spring time adjustment, more people encounter reduced sleep duration and an increase in disturbances in their sleep cycle. Such disruptions of sleep can lead to elevated heart rate, increased blood pressure, and a heightened risk of arrhythmias.\n",
    "\n",
    "For illustration we add the mediator \"Sleep Quality\" between 'daylight_saving_march' and 'hypertension.  -->\n",
    "We believe that the reason why causal discovery does not work is that the data is not Gaussian. Therefore we want to simulate our own data, corresponding to our graph.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "AGE: X_1 &\\leftarrow \\epsilon_1 & \\epsilon_1 &\\sim \\mathcal N(0,1)\\\\ \n",
    "INSURANCE PROVIDER: X_2 &\\leftarrow X_1 + \\epsilon_2 & \\epsilon_2 &\\sim \\mathcal N(0,0.7)\\\\\n",
    "ADMISSION TYPE: X_3 &\\leftarrow X_7 + \\epsilon_3 & \\epsilon_3 &\\sim \\mathcal N(0,1)\\\\\n",
    "GENDER: X_4 &\\leftarrow X_6 + \\epsilon_4 & \\epsilon_4 &\\sim \\mathcal N(0,1)\\\\\n",
    "HYPERTENSION: X_5 &\\leftarrow X_7 + X_4 + X_1 + X_2 + \\epsilon_5 & \\epsilon_5 &\\sim \\mathcal N(0,1)\\\\\n",
    "BILLING AMOUNT: X_6 &\\leftarrow X_1 + X_3 + \\epsilon_6 & \\epsilon_6 &\\sim \\mathcal N(0,1.5)\\\\\n",
    "DAYLIGHT SAVING MARCH: X_7 &\\leftarrow X_1 + \\epsilon_7 & \\epsilon_7 &\\sim \\mathcal N(0,1)\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=10000\n",
    "\n",
    "eps1 = normal(0, 1, n_samples)\n",
    "eps2 = normal(0, 0.7, n_samples)\n",
    "eps3 = normal(0, 1, n_samples)\n",
    "eps4 = normal(0, 1, n_samples)\n",
    "eps5 = normal(0, 1, n_samples)\n",
    "eps6 = normal(0, 1.5, n_samples)\n",
    "eps7 = normal(0, 1, n_samples)\n",
    "\n",
    "X1 = eps1\n",
    "X2 = X1 + eps2\n",
    "X7= X1 + eps7\n",
    "X3 = X7 + eps3\n",
    "X6 = X1 + X3 + eps6\n",
    "X4 = X6 + eps4\n",
    "X5 = X7 + X4 + X1 + X2 + eps5\n",
    "\n",
    "# we can plot scatter plots between any two variables to test for correlation\n",
    "plt.scatter(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X4, X7) # another correlation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(G)\n",
    "node_size = [800 if node in graph_variables else 200 for node in G.nodes]\n",
    "node_color = ['skyblue' if node in graph_variables else 'lightgray' for node in G.nodes]\n",
    "\n",
    "nx.draw(G, pos, with_labels=True, font_size=6, node_size=node_size, node_color=node_color, font_color='black', font_weight='bold', arrowsize=10)\n",
    "nx.write_gml(G, \"causal_graph.gml\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GENCDA.data_generation.relatedDataframe import RelatedDataframe\n",
    "from GENCDA.data_generation.randomDataframe import randomDataframe\n",
    "\n",
    "num_samples = 1500\n",
    "# Define a DAG\n",
    "graph_variables = ['Age', 'Gender', 'Insurance Provider', 'Billing Amount', \n",
    "                   'Admission Type', 'Hypertension', 'daylight_saving_march']\n",
    "\n",
    "edges = [\n",
    "    ('Age', 'Billing Amount'),                      \n",
    "    ('Age', 'Insurance Provider'),                 \n",
    "    ('Age', 'Hypertension'),                        \n",
    "    ('Gender', 'Hypertension'),                     \n",
    "    ('daylight_saving_march', 'Hypertension'),     \n",
    "    ('Admission Type', 'Billing Amount'),          \n",
    "    ('daylight_saving_march', 'Admission Type'),   \n",
    "    ('Age', 'daylight_saving_march'),            \n",
    "    ('Insurance Provider', 'Hypertension'),\n",
    "    ('Billing Amount', 'Gender')\n",
    "]\n",
    "\n",
    "dag = nx.to_networkx_graph(edges, create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_synthetic_df = pd.DataFrame({'Age': X1,'Insurance Provider': X2,'Admission Type': X3,'Gender': X4,'Hypertension': X5, 'Billing Amount': X6,'daylight_saving_march': X7})\n",
    "new_synthetic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply GES algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the GES on the newly generated syntehtic data\n",
    "new_skeleton = cdt.utils.graph.remove_indirect_links(skeleton, alg='aracne')\n",
    "model = cdt.causality.graph.GES()\n",
    "output_graph = model.predict(new_synthetic_df, new_skeleton)\n",
    "\n",
    "print(nx.adjacency_matrix(output_graph).todense())\n",
    "\n",
    "nx.draw(output_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply PC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the PC on the newly generated syntehtic data\n",
    "pc = cdt.causality.graph.PC(CItest=\"gaussian\", alpha=0.01)\n",
    "\n",
    "pc_graph = pc.create_graph_from_data(new_synthetic_df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(pc_graph, with_labels=True, node_size=100, node_color='w', edgecolors ='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply LINGAM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdt.causality.graph import LiNGAM\n",
    "\n",
    "obj = LiNGAM()\n",
    "output = obj.predict(new_synthetic_df)\n",
    "colors = ['red'  if (y,x) in pc_graph.edges() else 'black' for (x,y) in pc_graph.edges()]\n",
    "nx.draw(output, with_labels=True, node_size=100, node_color='w', edgecolors ='black', edge_color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in output.edges():\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply GIES algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIES\n",
    "from cdt.causality.graph import GIES\n",
    "\n",
    "obj = GIES()\n",
    "\n",
    "output = obj.predict(new_synthetic_df, dag)\n",
    "\n",
    "nx.draw_networkx(output, font_size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the best results when using PC algorithm. Be believe this happens because the data is gaussian. We almost reconstruct the original graph perfetly in fact. A score based method does not lead to very good results because. Most of the times the resulted graph is one where hypertension causes the daylight saving. Therefore, a constraint based algorithm works best in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We test how the daylight saving from March (when usually people's routine starts one hour earlier) has an effect on them being admitted to hospitals with a  hypertension diagnosis. We use a dataset from Kaggle containing synthetic data generated from a true distribution of such admissions. We conduct some data preprocessing where we remove some columns, where we encode the categorical values in numerical ones to be able to apply statistical tests. Be observe some dependencies and independencies in the data and therefore we come up with a graph and assumptions, such as:\n",
    "- age has an influence on the billing amount and insurance provider.\n",
    "\n",
    "From the independence test we find a surprising conclusion:\n",
    "- gender is cause by billing amount\n",
    "Maybe based on how much people's treatment costs gender can be identified.\n",
    "\n",
    "We identify the backdoor paths and conclude that we have to condition on Age in order to get the true causal effect of the daylight saving on people admitted with hypertension. We motivate why there are no frontdoor paths between the treatment and outcome and why instrumental variables cannot be used in our case given our available data.\n",
    "\n",
    "We use a matching propensity score to obtain a very slight positive effect that daylight saving march has on hypertension. We believe that the poor results from the causal estimands is due to the complex nature of our data and the assumptions the estimators make.\n",
    "\n",
    "Up until now we treated our analysis as if the graph was given. We apply causal discovery to our data to learn the causal graph. Unfortunately, the causal discovery techniques did not work on our data very well. We believe this is because our data does not have a Gaussian distribution. As future work, we could try and force our data to be Gaussian, or identify the distribution of our data to find better causal graphs. To prove our point, we generate some data according to the true graph and we apply causal discovery algorithms, both constraint-based and score-based.\n",
    "\n",
    "Generally, we believe this is a great starting point for investigating if the nature of our data to construct better results for our hypothesis. We did find surprising dependence relations in the data, but at other times common knowledge could be mapped with the graph.\n",
    "\n",
    "In conclusion, there is a very slight chance that the daylight saving in march has an effect on hypertension given the data we analysed. Maybe applying the same reasoning to other data could help get more generalized results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
